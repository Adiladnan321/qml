{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yZzPQ42CQ4j"
      },
      "source": [
        "## Multi-Class Quantum Convolutional Neural Networks\n",
        "\n",
        "We implement a QCNN trained to classify the digits of the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFhuxa5SCQ4l"
      },
      "outputs": [],
      "source": [
        "!pip install pennylane\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import inspect\n",
        "\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
        "from pennylane import numpy as np\n",
        "import autograd.numpy as anp\n",
        "\n",
        "n_qubit = 8 #number of qubit in the circuit\n",
        "encoding = 'amplitude' #choose the quantum encoding: 'amplitude' or 'angle'\n",
        "num_classes = 10 # choose how many classes: 4, 6, 8, 10\n",
        "all_samples = True #True if you want all the samples, False, if you want only 250 samples for each class\n",
        "seed = 43 #set to None to generate the seed randomly\n",
        "U_params = 15 #number of parameters of F_2 circuit\n",
        "num_layer = 1 #number of convolutional layer repetitions\n",
        "load_params = False #if True load parameters from a file\n",
        "opt = 'Adam' #choose the optimizer: Adam, QNGO, or GDO\n",
        "lr = 0.01 #learning rate\n",
        "epochs = 2 #number of epochs\n",
        "batch_size = 64 #size of batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74l8TEasCQ4m"
      },
      "source": [
        "Load the MNIST dataset: split it in train and test, take only 250 samples if all_samples == False.\n",
        "\n",
        "Take only 256 features if the amplitude encoding is applied, otherwise only 8 if the angle encoding is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTTnmx09CQ4m",
        "outputId": "e4e15c13-a310-406a-83dd-e4da51a5a8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of subset training data: (60000, 28, 28, 1)\n",
            "Shape of subset training labels: (60000,)\n",
            "Shape of subset training data: (60000, 28, 28, 1)\n",
            "Shape of subset training labels: (60000,)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "It loads the MNIST dataset and then it processes the dataset based on the encoding method, number of classes and if we want all the samples.\n",
        "param encoding: indicate the quantum encoding used: 'amplitude' or 'angle'\n",
        "param num_classes: number of classes to be predicted, which samples take from the dataset\n",
        "param all_samples: True if we want all the samples, False to take only 250 samples for each class\n",
        "param seed: random_state seed\n",
        "return X_train, X_test, Y_train, Y_test: the dataset divided in training and test set\n",
        "\"\"\"\n",
        "def data_load_and_process(encoding, num_classes, all_samples, seed):\n",
        "\tif seed != None:\n",
        "\t\ttf.random.set_seed(seed)\n",
        "\t\tnp.random.seed(seed)\n",
        "\n",
        "\t(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "\tx_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0\t # normalize the data\n",
        "\n",
        "\t#check is the user want all the samples\n",
        "\tif not all_samples:\n",
        "\t\tnum_examples_per_class = 250\n",
        "\t\tselected_indices = []\n",
        "\n",
        "\t\t# Iterate through each class to select 1000 examples\n",
        "\t\tfor class_label in range(10):\n",
        "\t\t\tindices = np.where(y_train == class_label)[0][:num_examples_per_class]\n",
        "\t\t\tselected_indices.extend(indices)\n",
        "\n",
        "\t\t# Filter the training data to contain only the selected examples\n",
        "\t\tx_train_subset = x_train[selected_indices]\n",
        "\t\ty_train_subset = y_train[selected_indices]\n",
        "\n",
        "\t\t# Shuffle the data\n",
        "\t\tshuffle_indices = np.random.permutation(len(x_train_subset))\n",
        "\t\tx_train = x_train_subset[shuffle_indices]\n",
        "\t\ty_train = y_train_subset[shuffle_indices]\n",
        "\n",
        "\tprint(\"Shape of subset training data:\", x_train.shape)\n",
        "\tprint(\"Shape of subset training labels:\", y_train.shape)\n",
        "\n",
        "\t#take only the number of classes selected\n",
        "\tmask_train = np.isin(y_train, range(0, num_classes))\n",
        "\tmask_test = np.isin(y_test, range(0, num_classes))\n",
        "\n",
        "\tX_train = x_train[mask_train]\n",
        "\tX_test = x_test[mask_test]\n",
        "\tY_train = y_train[mask_train]\n",
        "\tY_test = y_test[mask_test]\n",
        "\n",
        "\tprint(\"Shape of subset training data:\", X_train.shape)\n",
        "\tprint(\"Shape of subset training labels:\", Y_train.shape)\n",
        "\n",
        "\t#check which encoding is used\n",
        "\t#if amplitude encoding is used, then the 256 most important features are taken using PCA\n",
        "\tif encoding == 'amplitude':\n",
        "\t\tX_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "\t\tX_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\t\tpca = PCA(n_components = 256)\n",
        "\t\tX_train = pca.fit_transform(X_train_flat)\n",
        "\t\tX_test = pca.transform(X_test_flat)\n",
        "\t\treturn X_train, X_test, Y_train, Y_test\n",
        "\t#if amplitude encoding is used, then the 8 most important features are taken using PCA\n",
        "\telif encoding == 'angle':\n",
        "\t\tX_train = tf.image.resize(X_train[:], (784, 1)).numpy()\n",
        "\t\tX_test = tf.image.resize(X_test[:], (784, 1)).numpy()\n",
        "\t\tX_train, X_test = tf.squeeze(X_train), tf.squeeze(X_test)\n",
        "\n",
        "\t\tpca = PCA(8)\n",
        "\n",
        "\t\tX_train = pca.fit_transform(X_train)\n",
        "\t\tX_test = pca.transform(X_test)\n",
        "\n",
        "\t\t# Rescale for angle embedding\n",
        "\n",
        "\t\tX_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())),\\\n",
        "\t\t\t\t\t\t  (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
        "\t\treturn X_train, X_test, Y_train, Y_test\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = data_load_and_process(encoding, num_classes, all_samples, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZebjAIBwCQ4n"
      },
      "source": [
        "Define the QCNN:\n",
        "\n",
        "1) Create the two circuits which implement the convolutional layer and the circuit which implements the pooling operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpSsqMjtCQ4o"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "F_1 circuit of the paper\n",
        "param params: theta angle of the rotations. parameters to be trained\n",
        "param wires: qubits to apply the gates\n",
        "\"\"\"\n",
        "def CC14(params, wires):\n",
        "\t#U_CC14 r = 1\n",
        "\tfor i in range(0, len(wires)):\n",
        "\t\tqml.RY(params[i], wires=wires[i])\n",
        "\tfor i in range(0, len(wires)):\n",
        "\t\tqml.CRX(params[i + len(wires)], wires=[wires[(i - 1) % len(wires)], wires[i]])\n",
        "\n",
        "\n",
        "\n",
        "\t#U_CC14 r = -1 or 3\n",
        "\tfor i in range(0, len(wires)):\n",
        "\t\tqml.RY(params[i + 2 * len(wires)], wires=wires[i])\n",
        "\n",
        "\tif len(wires) % 3 == 0 or len(wires) == 2:\n",
        "\t\tfor i in range(len(wires) - 1, -1, -1):\n",
        "\t\t\tqml.CRX(params[i + 3 * len(wires)], wires=[wires[i], wires[(i-1) % len(wires)]])\n",
        "\n",
        "\telse:\n",
        "\t\tcontrol = len(wires) - 1\n",
        "\t\ttarget = (control + 3) % len(wires)\n",
        "\t\tfor i in range(len(wires) - 1, -1, -1):\n",
        "\t\t\tqml.CRX(params[i + 3 * len(wires)], wires=[wires[control], wires[target]])\n",
        "\n",
        "\t\t\tcontrol = target\n",
        "\t\t\ttarget = (control + 3) % len(wires)\n",
        "\n",
        "\"\"\"\n",
        "F_2 circuit of the paper\n",
        "param params: theta angle of the rotations. parameters to be trained\n",
        "param wires: qubits to apply the gates\n",
        "\"\"\"\n",
        "def U_SU4(params, wires): # 15 params\n",
        "\tqml.U3(params[0], params[1], params[2], wires=wires[0])\n",
        "\tqml.U3(params[3], params[4], params[5], wires=wires[1])\n",
        "\tqml.CNOT(wires=[wires[0], wires[1]])\n",
        "\tqml.RY(params[6], wires=wires[0])\n",
        "\tqml.RZ(params[7], wires=wires[1])\n",
        "\tqml.CNOT(wires=[wires[1], wires[0]])\n",
        "\tqml.RY(params[8], wires=wires[0])\n",
        "\tqml.CNOT(wires=[wires[0], wires[1]])\n",
        "\tqml.U3(params[9], params[10], params[11], wires=wires[0])\n",
        "\tqml.U3(params[12], params[13], params[14], wires=wires[1])\n",
        "\n",
        "\"\"\"\n",
        "It implements the pooling circuit\n",
        "param params: theta angle of the rotations. parameters to be trained\n",
        "param wires: qubits to apply the gates\n",
        "\"\"\"\n",
        "def Pooling_ansatz(params, wires): #2 params\n",
        "\tqml.CRZ(params[0], wires=[wires[0], wires[1]])\n",
        "\tqml.PauliX(wires=wires[0])\n",
        "\tqml.CRX(params[1], wires=[wires[0], wires[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_w5m48_CQ4o"
      },
      "source": [
        "2) create the structure of the convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueZosmwaCQ4o"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Quantum Circuits for Convolutional layers\n",
        "param U: unitary that implements the convolution\n",
        "param params: theta angle of the rotations. parameters to be trained\n",
        "param U_params: number of parameters which implement a single block of the F_2 circuit\n",
        "param num_layer: number of repetition of the convolutional layer\n",
        "param qubits: array that indicate to which qubit apply the convolutional layer\n",
        "\"\"\"\n",
        "def conv_layer(U, params, U_params, num_layer, qubits):\n",
        "\t\tparam0 = 0\n",
        "\t\tparam1 = len(qubits) * 2\n",
        "\n",
        "\t\t#add f_1 circuit\n",
        "\t\tfor l in range(num_layer):\n",
        "\t\t\tif len(qubits) == 8: #if it is the first layer, the F_1 circuit is \"divided\"\n",
        "\t\t\t\tfor i in range(0, len(qubits), len(qubits)//2):\n",
        "\t\t\t\t\tU(params[param0: param1], wires = qubits[i: i + len(qubits)//2])\n",
        "\t\t\telse:\n",
        "\t\t\t\tparam1 += len(qubits) * 2\n",
        "\t\t\t\tU(params[param0: param1], wires = qubits[0: len(qubits)])\n",
        "\n",
        "\t\t\t#now add the two-qubit circuit (F_2)\n",
        "\t\t\tparam0 = param1\n",
        "\t\t\tparam1 += U_params\n",
        "\t\t\tfor i in range(0, len(qubits), 2):\n",
        "\t\t\t\tU_SU4(params[param0: param1], wires = [qubits[i % len(qubits)], qubits[(i + 1) % len(qubits)]])\n",
        "\n",
        "\t\t\tfor i in range(1, len(qubits), 2):\n",
        "\t\t\t\tU_SU4(params[param0: param1], wires = [qubits[i % len(qubits)], qubits[(i + 1) % len(qubits)]])\n",
        "\n",
        "\t\t\tparam0 = param1\n",
        "\t\t\tparam1 += len(qubits) * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFpr8rSYCQ4o"
      },
      "source": [
        "3) create the structure of the pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15JvQVqfCQ4o"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Quantum Circuits for Pooling layers\n",
        "param V: unitary which implements the pooling operation\n",
        "param params: theta angle of the rotations. parameters to be trained\n",
        "\"\"\"\n",
        "def pooling_layer1(V, params):\n",
        "\tV(params, wires=[7, 6])\n",
        "\tV(params, wires=[1, 0])\n",
        "\n",
        "def pooling_layer2(V, params):\n",
        "\tV(params, wires=[3, 2])\n",
        "\tV(params, wires=[5, 4])\n",
        "\n",
        "def pooling_layer3(V, params, num_classes):\n",
        "\tif num_classes == 4: #if we need only 4 classes. we trace out another qubit\n",
        "\t\tV(params, wires=[2,0])\n",
        "\tV(params, wires=[6,4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw-D7rNdCQ4p"
      },
      "source": [
        "4) create the structure of the QCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfozq5POCQ4p"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "It implements the structure of the QCNN\n",
        "param U: unitary F_1\n",
        "param params: theta angle of the rotations. parameters to be trained\n",
        "param U_params: number of parameters which implement a single block of the F_2 circuit\n",
        "param num_classes: how many classes the QNN has to predict\n",
        "param num_layer: number of repetition of the convolutional layer\n",
        "\"\"\"\n",
        "def QCNN_structure(U, params, U_params, num_classes, num_layer):\n",
        "\t#divide the number of parameters for each layer: conv layer1, pooling layer 1, conv layer 2, ...\n",
        "\t#U_params indicates the number of parameters of the F_2 circuit (the circuit applied to couple of adjacent qubit)\n",
        "\t#n_qubit * 2: is the number of parameters for the circuit F_1\n",
        "\tparam1CL = params[0: (U_params + n_qubit * 2) * num_layer]\n",
        "\tparam1PL = params[(U_params + n_qubit * 2) * num_layer: ((U_params + n_qubit * 2) * num_layer) + 2]\n",
        "\n",
        "\tparam2CL = params[((U_params + n_qubit * 2) * num_layer) + 2: ((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer)]\n",
        "\tparam2PL = params[((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer):\n",
        "\t\t\t\t\t  ((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer) + 2]\n",
        "\n",
        "\tparam3CL = params[((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer) + 2:\n",
        "\t\t\t\t\t  ((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer) + 2 + ((U_params + n_qubit * 2) * num_layer)]\n",
        "\n",
        "\t#apply the circuits\n",
        "\tconv_layer(U, param1CL, U_params, num_layer, range(n_qubit))\n",
        "\tpooling_layer1(Pooling_ansatz, param1PL)\n",
        "\n",
        "\tconv_layer(U, param2CL, U_params, num_layer, [0, 2, 3, 4, 5, 6])\n",
        "\tpooling_layer2(Pooling_ansatz, param2PL)\n",
        "\n",
        "\tconv_layer(U, param3CL, U_params, num_layer, [0, 2, 4, 6])\n",
        "\n",
        "\t#if we have only 4, 6 or 8 classes, then we need another pooling layer and we need to trace out:\n",
        "\t#another qubit if we have 6 or 8 classes, because we need only 3 qubits to represent 6 or 8 classes\n",
        "\t#2 qubits if we have 4 classes, because we need only 2 qubits to represent 4 classes/states\n",
        "\t#if we have 10 classes, then we don't apply another pooling layer, because we need 4 qubits\n",
        "\tif num_classes == 4 or num_classes == 6 or num_classes == 8:\n",
        "\t\tparam3PL = params[((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer) + 2 + ((U_params + n_qubit * 2) * num_layer):\n",
        "\t\t\t\t\t\t ((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer) + 2 + ((U_params + n_qubit * 2) * num_layer) + 2]\n",
        "\n",
        "\t\tpooling_layer3(Pooling_ansatz, param3PL, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y66fnLZACQ4p"
      },
      "source": [
        "Create the QCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQe9We7NCQ4p"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "define the simulator and the QCNN: encoding + VQC + measurement\n",
        "param X: sample in input\n",
        "param params: theta angle of the rotations. parameters to be trained\n",
        "param U_params: number of parameters which implement a single block of the F_2 circuit\n",
        "param embedding_type: which encoding is chosen\n",
        "param num_classes: how many classes the QNN has to predict\n",
        "param num_layer: number of repetition of the convolutional layer\n",
        "return result: the probabilities of the states, which are associated to the MNIST classes\n",
        "\"\"\"\n",
        "dev = qml.device('default.qubit', wires = n_qubit)\n",
        "@qml.qnode(dev)\n",
        "def QCNN(X, params, U_params, embedding_type='amplitude', num_classes=10, num_layer = 1):\n",
        "\t# Data Embedding\n",
        "\tif embedding_type == 'amplitude':\n",
        "\t\tAmplitudeEmbedding(X, wires=range(8), normalize=True)\n",
        "\telif embedding_type == 'angle':\n",
        "\t\tAngleEmbedding(X, wires=range(8), rotation='Y')\n",
        "\n",
        "\t# Create the VQC\n",
        "\tQCNN_structure(CC14, params, U_params, num_classes, num_layer)\n",
        "\n",
        "\t#Measures the necessary qubits\n",
        "\tif num_classes == 4:\n",
        "\t\tresult = qml.probs(wires=[0, 4])\n",
        "\telif num_classes == 6:\n",
        "\t\tresult = qml.probs(wires=[0, 2, 4])\n",
        "\telif num_classes == 8:\n",
        "\t\tresult = qml.probs(wires=[0, 2, 4])\n",
        "\telse:\n",
        "\t\tresult = qml.probs(wires=[0, 2, 4, 6])\n",
        "\n",
        "\treturn result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zmUDbjQCQ4p"
      },
      "source": [
        "Training Step:\n",
        "\n",
        "1) define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjcpToA0CQ4p"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "It computes the cross-entropy loss\n",
        "param labels: correct classes of the Training set\n",
        "param predictions: classes predicted by the QCNN\n",
        "param num_classes: number of classes\n",
        "return loss: average loss\n",
        "\"\"\"\n",
        "def cross_entropy(labels, predictions, num_classes):\n",
        "\tepsilon = 1e-15\n",
        "\tnum_samples = len(labels)\n",
        "\n",
        "\tnum_classes = len(predictions[0])\n",
        "\tY_true_one_hot = anp.eye(num_classes)[labels]\n",
        "\n",
        "\tloss = 0.0\n",
        "\tfor i in range(num_samples):\n",
        "\t\tpredictions[i] = anp.clip(predictions[i], epsilon, 1 - epsilon)\n",
        "\t\tloss -= anp.sum(Y_true_one_hot[i] * anp.log(predictions[i]))\n",
        "\n",
        "\n",
        "\treturn loss / num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRdIkCAsCQ4p"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "It executes the circuit for each image of the dataset (divided in batches)\n",
        "param calculate the loss function\n",
        "param params: the angle to be trained\n",
        "param X: batches of the training set\n",
        "param Y: batches of the training set\n",
        "param U_params: number of parameters which implement a single block of the F_2 circuit\n",
        "param embedding_type: indicate the chosen encoding )\n",
        "param circ_layer: number of repetitions of the convolutional layer\n",
        "return loss: average loss\n",
        "\"\"\"\n",
        "def cost(params, X, Y, U_params, embedding_type, num_classes, circ_layer):\n",
        "\tpredictions = [QCNN(x, params, U_params, embedding_type, num_classes=num_classes, layer = circ_layer) for x in X]\n",
        "\n",
        "\n",
        "\tloss = cross_entropy(Y, predictions, num_classes)\n",
        "\n",
        "\treturn loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pa1Sz2JCQ4p"
      },
      "source": [
        "2) Execute the training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbVoPoiOCQ4p",
        "outputId": "79eb6d4b-de38-4173-9beb-b8e0c0e8d54e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss History for circuit with amplitude\n",
            "EPOCH:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Marco\\miniconda3\\envs\\pl_cpu_jup\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:698: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  onp.add.at(A, idx, x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration:  0  cost:  2.793639592510273\n",
            "iteration:  6400  cost:  2.3454968749014977\n",
            "iteration:  12800  cost:  2.350804201469498\n",
            "iteration:  19200  cost:  2.390058187012758\n",
            "iteration:  25600  cost:  2.145615944178888\n",
            "iteration:  32000  cost:  2.1590629945116815\n",
            "iteration:  38400  cost:  2.1028156791251527\n",
            "iteration:  44800  cost:  2.269390313856259\n",
            "iteration:  51200  cost:  2.2079282103008855\n",
            "iteration:  57600  cost:  2.271460262932687\n",
            "EPOCH:  1\n",
            "iteration:  0  cost:  2.198988499641296\n",
            "iteration:  6400  cost:  2.141810916788035\n",
            "iteration:  12800  cost:  2.0999173864445906\n",
            "iteration:  19200  cost:  2.189340618483039\n",
            "iteration:  25600  cost:  2.0646491568359924\n",
            "iteration:  32000  cost:  2.132142383087968\n",
            "iteration:  38400  cost:  2.028629969450609\n",
            "iteration:  44800  cost:  2.249857211386858\n",
            "iteration:  51200  cost:  2.1752603866711544\n",
            "iteration:  57600  cost:  2.0863983708256084\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "It executes the training of the QNN\n",
        "param X_train: X training set\n",
        "param Y_train: Y training set\n",
        "param U_params: number of parameters which implement a single block of the F_2 circuit\n",
        "param embedding_type: the encoding method used\n",
        "param num_classes: number of classes\n",
        "param num_layer: number of repetitions of conv layer\n",
        "param loadParams: if True the parameters are loaded from a file (used to continue a stopped training)\n",
        "param optimizer: the optimizer used\n",
        "param learning_rate: learning rate of the optimizer\n",
        "param epochs: number of epochs\n",
        "param all_samples: it all the samples are used\n",
        "param batch_size: size of the batches\n",
        "param seed: if None a random seed is used, otherwise the value in the variable\n",
        "return params: the trained parameters\n",
        "\"\"\"\n",
        "def circuit_training(X_train, Y_train, U_params, embedding_type, num_classes, num_layer, loadParams, optimizer, learning_rate, epochs, all_samples, batch_size, seed):\n",
        "\tif seed != None:\n",
        "\t\tnp.random.seed(seed)\n",
        "\t\tanp.random.seed(seed)\n",
        "\n",
        "\t#calculate the number of parameters\n",
        "\tif num_classes == 10:\n",
        "\t\ttotal_params =\t((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer) + 2 + ((U_params + n_qubit * 2) * num_layer)\n",
        "\telse: #we have to add another pooling layer at the end, so we need two parameters\n",
        "\t\ttotal_params =\t((U_params + n_qubit * 2) * num_layer) + 2 + ((U_params + (n_qubit - 2) * 4) * num_layer) + 2 + ((U_params + n_qubit * 2) * num_layer) + 2\n",
        "\n",
        "\t#laod the parameters\n",
        "\tif not loadParams:\n",
        "\t\tparams = np.random.randn(total_params, requires_grad=True)\n",
        "\telse:\n",
        "\t\tfileParams = open('params' + 'L' + str(num_layer) + 'LR' + str(learning_rate) + optimizer + 'C' + str(num_classes) + str(all_samples) + '.obj', 'rb')\n",
        "\n",
        "\t\tparams = pickle.load(fileParams)\n",
        "\t\tfileParams.close()\n",
        "\t\tprint(params)\n",
        "\n",
        "\t#choose the optimizer\n",
        "\tif optimizer == 'Adam':\n",
        "\t\topt = qml.AdamOptimizer(stepsize=learning_rate)\n",
        "\telif optimizer == 'GDO':\n",
        "\t\topt = qml.GradientDescentOptimizer(stepsize=learning_rate)\n",
        "\telse:\n",
        "\t\topt = qml.QNGOptimizer(stepsize=learning_rate)\n",
        "\n",
        "\t#start the training\n",
        "\tloss_history = []\n",
        "\tgrad_vals = []\n",
        "\tfor e in range(0, epochs):\n",
        "\t\tprint(\"EPOCH: \", e)\n",
        "\t\tfor b in range(0, len(X_train), batch_size):\n",
        "\t\t\tif (b + batch_size) <= len(X_train):\n",
        "\t\t\t\tX_batch = [X_train[i] for i in range(b, b + batch_size)]\n",
        "\t\t\t\tY_batch = [Y_train[i] for i in range(b, b + batch_size)]\n",
        "\t\t\telse:\n",
        "\t\t\t\tX_batch = [X_train[i] for i in range(b, len(X_train))]\n",
        "\t\t\t\tY_batch = [Y_train[i] for i in range(b, len(X_train))]\n",
        "\n",
        "\t\t\tif optimizer == 'QNGO':\n",
        "\t\t\t\tmetric_fn = lambda p: qml.metric_tensor(QCNN, approx=\"block-diag\")(X_batch, p, U_params, embedding_type, num_classes, num_layer)\n",
        "\t\t\t\tparams, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U_params, embedding_type, num_classes, num_layer),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t \tparams, metric_tensor_fn=metric_fn)\n",
        "\t\t\telse:\n",
        "\t\t\t\tparams, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U_params, embedding_type, num_classes, num_layer),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t \tparams)\n",
        "\n",
        "\n",
        "\t\t\tif b % (batch_size * 100) == 0:\n",
        "\t\t\t\tprint(\"iteration: \", b, \" cost: \", cost_new)\n",
        "\t\t\t\t\"\"\"\n",
        "\t\t\t\tloss_history.append(cost_new)\n",
        "\t\t\t\tgradient_fn = qml.grad(cost)\n",
        "\t\t\t\tgradients = gradient_fn(params, X_batch, Y_batch, U, U_params, embedding_type, cost_fn, num_classes, num_layer)\n",
        "\t\t\t\tgrad_vals.append(gradients[-1])\n",
        "\t\t\t\tprint(gradients)\n",
        "\t\t\t\tprint(\"var \", np.var(grad_vals))\n",
        "\t\t\t\tprint(\"mean grad: \", np.mean(grad_vals))\n",
        "\t\t\t\t\"\"\"\n",
        "\n",
        "\n",
        "\t\t#save the novel parameters at the end of each epoch\n",
        "\t\tfileParams = open('params' + 'L' + str(num_layer) + 'LR' + str(learning_rate) + optimizer + 'C' + str(num_classes) + str(all_samples) + '.obj', 'wb')\n",
        "\n",
        "\n",
        "\t\tpickle.dump(params, fileParams)\n",
        "\t\tfileParams.close()\n",
        "\treturn params\n",
        "\n",
        "print(\"Loss History for circuit with \" + encoding)\n",
        "trained_params = circuit_training(X_train, Y_train, U_params, encoding, num_classes, num_layer, load_params,\n",
        "\t\t\t\t\t\t\t\topt, lr, epochs, all_samples, batch_size, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leV0GanfCQ4q"
      },
      "source": [
        "Infere on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UqlOiFrCQ4q",
        "outputId": "8d2dc671-3ec1-46a5-e1e1-ea32d2af8b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5674\n",
            "[[[8613  407]\n",
            "  [ 447  533]]\n",
            "\n",
            " [[8064  801]\n",
            "  [  89 1046]]\n",
            "\n",
            " [[8465  503]\n",
            "  [ 479  553]]\n",
            "\n",
            " [[8758  232]\n",
            "  [ 625  385]]\n",
            "\n",
            " [[8284  734]\n",
            "  [ 445  537]]\n",
            "\n",
            " [[8886  222]\n",
            "  [ 659  233]]\n",
            "\n",
            " [[8660  382]\n",
            "  [ 234  724]]\n",
            "\n",
            " [[8747  225]\n",
            "  [ 251  777]]\n",
            "\n",
            " [[8736  290]\n",
            "  [ 490  484]]\n",
            "\n",
            " [[8461  530]\n",
            "  [ 607  402]]]\n",
            "precision 0: 0.5670212765957446\n",
            "recall 0: 0.5438775510204081\n",
            "f1 0: 0.5552083333333332\n",
            "precision 1: 0.5663237682728749\n",
            "recall 1: 0.9215859030837005\n",
            "f1 1: 0.7015425888665324\n",
            "precision 2: 0.5236742424242424\n",
            "recall 2: 0.5358527131782945\n",
            "f1 2: 0.5296934865900381\n",
            "precision 3: 0.6239870340356564\n",
            "recall 3: 0.3811881188118812\n",
            "f1 3: 0.47326367547633663\n",
            "precision 4: 0.4225019669551534\n",
            "recall 4: 0.5468431771894093\n",
            "f1 4: 0.4766977363515312\n",
            "precision 5: 0.512087912087912\n",
            "recall 5: 0.26121076233183854\n",
            "f1 5: 0.345953971789161\n",
            "precision 6: 0.6546112115732369\n",
            "recall 6: 0.755741127348643\n",
            "f1 6: 0.701550387596899\n",
            "precision 7: 0.7754491017964071\n",
            "recall 7: 0.7558365758754864\n",
            "f1 7: 0.7655172413793102\n",
            "precision 8: 0.6253229974160207\n",
            "recall 8: 0.49691991786447637\n",
            "f1 8: 0.5537757437070937\n",
            "precision 9: 0.4313304721030043\n",
            "recall 9: 0.398414271555996\n",
            "f1 9: 0.4142194744976815\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "It computes the accuracy on the test set\n",
        "param predictions: classes predicted\n",
        "param labels: true classes\n",
        "param num_classes: number of classes\n",
        "return accuracy: accuracy\n",
        "\"\"\"\n",
        "def accuracy_multi(predictions, labels, num_classes):\n",
        "\tcorrect_predictions = 0\n",
        "\n",
        "\n",
        "\tfor l, p in zip(labels, predictions):\n",
        "\t\tp2 = []\n",
        "\t\tfor i in range(0, num_classes):\n",
        "\t\t\tp2.append(p[i])\n",
        "\t\tpredicted_class = np.argmax(p2)\t# Find the index of the predicted class with highest probability\n",
        "\t\tif predicted_class == l:\n",
        "\t\t\tcorrect_predictions += 1\n",
        "\n",
        "\taccuracy = correct_predictions / len(labels)\n",
        "\treturn accuracy\n",
        "\n",
        "\"\"\"\n",
        "It computes the precision, recall, F1 score and Confusion Matrix on the test set\n",
        "param predictions: classes predicted\n",
        "param labels: true classes\n",
        "param num_classes: number of classes\n",
        "return accuracy: accuracy\n",
        "\"\"\"\n",
        "def accuracy_test_multiclass(predictions, label, num_classes):\n",
        "\t#confusion matrix\n",
        "\n",
        "\tpreds_np = np.array(predictions)\n",
        "\tpreds = np.argmax(preds_np[:, :num_classes], axis = 1)\n",
        "\n",
        "\tconf_mat = multilabel_confusion_matrix(label, preds, labels = list(range(num_classes)))\n",
        "\tprint(conf_mat)\n",
        "\tprecision = []\n",
        "\trecall = []\n",
        "\tf1 = []\n",
        "\ti = 0\n",
        "\tfor c in conf_mat:\n",
        "\t\tprecision.append(c[1][1] / (c[1][1] + c[0][1]))\n",
        "\t\trecall.append(c[1][1] / (c[1][1] + c[1][0]))\n",
        "\t\tf1.append(2 * (precision[i] * recall[i]) / (precision[i] + recall[i] + np.finfo(float).eps))\n",
        "\n",
        "\t\tprint(\"precision \" + str(i) + \": \" + str(precision[i]))\n",
        "\t\tprint(\"recall \" + str(i) + \": \" + str(recall[i]))\n",
        "\t\tprint(\"f1 \" + str(i) + \": \" + str(f1[i]))\n",
        "\t\ti += 1\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for x in X_test:\n",
        "\tpredictions.append(QCNN(x, trained_params, U_params, encoding, num_classes, num_layer))\n",
        "\n",
        "accuracy = accuracy_multi(predictions, Y_test, num_classes)\n",
        "print(\"Accuracy: \" + str(accuracy))\n",
        "accuracy_test_multiclass(predictions, Y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajw4YjgPCQ4q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_gs7T1cfDCMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "DkGu568DGn_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L# New Section"
      ],
      "metadata": {
        "id": "7jmSS3UNEVJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning shallow quantum circuits with local inversions and circuit sewing"
      ],
      "metadata": {
        "id": "kk-Pk35xEfW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Visualisation"
      ],
      "metadata": {
        "id": "1AGe_qsQEioe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane\n",
        "import pennylane as qml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a quantum device with 4 qubits\n",
        "dev = qml.device('default.qubit', wires=4)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def U_test():\n",
        "    # Apply Hadamard gates to all qubits\n",
        "    for i in range(4):\n",
        "        qml.Hadamard(wires=i)\n",
        "\n",
        "    # Apply CNOT gates\n",
        "    qml.CNOT(wires=(1, 2))\n",
        "    qml.CNOT(wires=(2, 3))\n",
        "    qml.CNOT(wires=(0, 1))\n",
        "\n",
        "# Draw the circuit\n",
        "circuit_diagram = qml.draw(U_test)()\n",
        "print(circuit_diagram)\n",
        "\n",
        "# Optionally, visualize using matplotlib (not directly supported by draw_mpl)\n",
        "# Instead, we can use draw() to get a textual representation or use other libraries for graphical representation.\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.text(0.5, 0.5, circuit_diagram, fontsize=12, ha='center', va='center')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UN_h34MnElNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Local Inversion"
      ],
      "metadata": {
        "id": "qGyBHV79Ep2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def U_test():\n",
        "    for i in range(4):\n",
        "        qml.Hadamard(i)\n",
        "    qml.CNOT((1, 2))\n",
        "    qml.CNOT((2, 3))\n",
        "    qml.CNOT((0, 1))\n",
        "\n",
        "qml.draw_mpl(U_test)()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xJTd9qFREshr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Circuit Sewing"
      ],
      "metadata": {
        "id": "LY2L3rAOEueQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=3, shots=1024)\n",
        "\n",
        "# Define the quantum teleportation circuit\n",
        "@qml.qnode(dev)\n",
        "def teleportation_circuit():\n",
        "    # Create entanglement between qubits 1 and 2\n",
        "    qml.Hadamard(wires=1)\n",
        "    qml.CNOT(wires=[1, 2])\n",
        "\n",
        "    # Prepare an arbitrary state on qubit 0 (e.g., |+>)\n",
        "    qml.Hadamard(wires=0)\n",
        "\n",
        "    # Bell state measurement on qubits 0 and 1\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.Hadamard(wires=0)\n",
        "\n",
        "    # Measure qubits 0 and 1\n",
        "    m0 = qml.measure(wires=0)\n",
        "    m1 = qml.measure(wires=1)\n",
        "\n",
        "    # Conditional operations on qubit 2 using qml.cond\n",
        "    qml.cond(m0, qml.PauliX)(wires=2)\n",
        "    qml.cond(m1, qml.PauliZ)(wires=2)\n",
        "\n",
        "    # Return the measurement of qubit 2\n",
        "    return qml.sample(wires=2)\n",
        "\n",
        "# Visualize the circuit before execution\n",
        "circuit_drawer = qml.draw(teleportation_circuit)\n",
        "print(\"Quantum Teleportation Circuit:\")\n",
        "print(circuit_drawer())\n",
        "\n",
        "# Execute the circuit\n",
        "results = teleportation_circuit()\n",
        "\n",
        "# Count the measurement results\n",
        "counts = np.bincount(results, minlength=2)\n",
        "\n",
        "# Plot the histogram of results\n",
        "plt.bar([\"0\", \"1\"], counts)\n",
        "plt.xlabel(\"Qubit 2 State\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.title(\"Quantum Teleportation Result on Qubit 2\")\n",
        "plt.show()\n",
        "\n",
        "# Display the executed circuit with conditional operations applied\n",
        "print(\"\\nExecuted Quantum Teleportation Circuit with Conditional Operations:\")\n",
        "print(circuit_drawer())"
      ],
      "metadata": {
        "id": "f_bVZxezExFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Quantum Teleportation"
      ],
      "metadata": {
        "id": "8rTjtbIGEznx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=3, shots=1024)\n",
        "\n",
        "# Define the quantum teleportation circuit\n",
        "@qml.qnode(dev)\n",
        "def teleportation_circuit():\n",
        "    # Create entanglement between qubits 1 and 2\n",
        "    qml.Hadamard(wires=1)\n",
        "    qml.CNOT(wires=[1, 2])\n",
        "\n",
        "    # Prepare an arbitrary state on qubit 0 (e.g., |+>)\n",
        "    qml.Hadamard(wires=0)\n",
        "\n",
        "    # Bell state measurement on qubits 0 and 1\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.Hadamard(wires=0)\n",
        "\n",
        "    # Measure qubits 0 and 1\n",
        "    m0 = qml.measure(wires=0)\n",
        "    m1 = qml.measure(wires=1)\n",
        "\n",
        "    # Conditional operations on qubit 2 using qml.cond\n",
        "    qml.cond(m0, qml.PauliX)(wires=2)\n",
        "    qml.cond(m1, qml.PauliZ)(wires=2)\n",
        "\n",
        "    # Return the measurement of qubit 2\n",
        "    return qml.sample(wires=2)\n",
        "\n",
        "# Visualize the circuit before execution\n",
        "circuit_drawer = qml.draw(teleportation_circuit)\n",
        "print(\"Quantum Teleportation Circuit:\")\n",
        "print(circuit_drawer())\n",
        "\n",
        "# Execute the circuit\n",
        "results = teleportation_circuit()\n",
        "\n",
        "# Count the measurement results\n",
        "counts = np.bincount(results, minlength=2)\n",
        "\n",
        "# Plot the histogram of results\n",
        "plt.bar([\"0\", \"1\"], counts)\n",
        "plt.xlabel(\"Qubit 2 State\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.title(\"Quantum Teleportation Result on Qubit 2\")\n",
        "plt.show()\n",
        "\n",
        "# Display the executed circuit with conditional operations applied\n",
        "print(\"\\nExecuted Quantum Teleportation Circuit with Conditional Operations:\")\n",
        "print(circuit_drawer())"
      ],
      "metadata": {
        "id": "esB1bu1ZE19o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "dzxee-EXE4qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generalization in QML from few training data"
      ],
      "metadata": {
        "id": "NOYP6B1xE_yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import seaborn as sns\n",
        "import jax;\n",
        "\n",
        "jax.config.update('jax_platform_name', 'cpu')\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import optax  # optimization using jax\n",
        "\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "\n",
        "sns.set()\n",
        "\n",
        "seed = 0\n",
        "rng = np.random.default_rng(seed=seed)"
      ],
      "metadata": {
        "id": "u0gZYwyqFTWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breaking down the layers"
      ],
      "metadata": {
        "id": "CECkfL_QFi6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_layer(weights, wires, skip_first_layer=True):\n",
        "    \"\"\"Adds a convolutional layer to a circuit.\n",
        "    Args:\n",
        "        weights (np.array): 1D array with 15 weights of the parametrized gates.\n",
        "        wires (list[int]): Wires where the convolutional layer acts on.\n",
        "        skip_first_layer (bool): Skips the first two U3 gates of a layer.\n",
        "    \"\"\"\n",
        "    n_wires = len(wires)\n",
        "    assert n_wires >= 3, \"this circuit is too small!\"\n",
        "\n",
        "    for p in [0, 1]:\n",
        "        for indx, w in enumerate(wires):\n",
        "            if indx % 2 == p and indx < n_wires - 1:\n",
        "                if indx % 2 == 0 and not skip_first_layer:\n",
        "                    qml.U3(*weights[:3], wires=[w])\n",
        "                    qml.U3(*weights[3:6], wires=[wires[indx + 1]])\n",
        "                qml.IsingXX(weights[6], wires=[w, wires[indx + 1]])\n",
        "                qml.IsingYY(weights[7], wires=[w, wires[indx + 1]])\n",
        "                qml.IsingZZ(weights[8], wires=[w, wires[indx + 1]])\n",
        "                qml.U3(*weights[9:12], wires=[w])\n",
        "                qml.U3(*weights[12:], wires=[wires[indx + 1]])"
      ],
      "metadata": {
        "id": "W68mX1PDFjtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pooling_layer(weights, wires):\n",
        "    \"\"\"Adds a pooling layer to a circuit.\n",
        "    Args:\n",
        "        weights (np.array): Array with the weights of the conditional U3 gate.\n",
        "        wires (list[int]): List of wires to apply the pooling layer on.\n",
        "    \"\"\"\n",
        "    n_wires = len(wires)\n",
        "    assert len(wires) >= 2, \"this circuit is too small!\"\n",
        "\n",
        "    for indx, w in enumerate(wires):\n",
        "        if indx % 2 == 1 and indx < n_wires:\n",
        "            m_outcome = qml.measure(w)\n",
        "            qml.cond(m_outcome, qml.U3)(*weights, wires=wires[indx - 1])"
      ],
      "metadata": {
        "id": "dW6pxd2yFpfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_and_pooling(kernel_weights, n_wires, skip_first_layer=True):\n",
        "    \"\"\"Apply both the convolutional and pooling layer.\"\"\"\n",
        "    convolutional_layer(kernel_weights[:15], n_wires, skip_first_layer=skip_first_layer)\n",
        "    pooling_layer(kernel_weights[15:], n_wires)\n",
        "\n",
        "\n",
        "def dense_layer(weights, wires):\n",
        "    \"\"\"Apply an arbitrary unitary gate to a specified set of wires.\"\"\"\n",
        "    qml.ArbitraryUnitary(weights, wires)\n",
        "\n",
        "\n",
        "num_wires = 6\n",
        "device = qml.device(\"default.qubit\", wires=num_wires)\n",
        "\n",
        "\n",
        "@qml.qnode(device)\n",
        "def conv_net(weights, last_layer_weights, features):\n",
        "    \"\"\"Define the QCNN circuit\n",
        "    Args:\n",
        "        weights (np.array): Parameters of the convolution and pool layers.\n",
        "        last_layer_weights (np.array): Parameters of the last dense layer.\n",
        "        features (np.array): Input data to be embedded using AmplitudEmbedding.\"\"\"\n",
        "\n",
        "    layers = weights.shape[1]\n",
        "    wires = list(range(num_wires))\n",
        "\n",
        "    # inputs the state input_state\n",
        "    qml.AmplitudeEmbedding(features=features, wires=wires, pad_with=0.5)\n",
        "    qml.Barrier(wires=wires, only_visual=True)\n",
        "\n",
        "    # adds convolutional and pooling layers\n",
        "    for j in range(layers):\n",
        "        conv_and_pooling(weights[:, j], wires, skip_first_layer=(not j == 0))\n",
        "        wires = wires[::2]\n",
        "        qml.Barrier(wires=wires, only_visual=True)\n",
        "\n",
        "    assert last_layer_weights.size == 4 ** (len(wires)) - 1, (\n",
        "        \"The size of the last layer weights vector is incorrect!\"\n",
        "        f\" \\n Expected {4 ** (len(wires)) - 1}, Given {last_layer_weights.size}\"\n",
        "    )\n",
        "    dense_layer(last_layer_weights, wires)\n",
        "    return qml.probs(wires=(0))\n",
        "\n",
        "\n",
        "fig, ax = qml.draw_mpl(conv_net)(\n",
        "    np.random.rand(18, 2), np.random.rand(4 ** 2 - 1), np.random.rand(2 ** num_wires)\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nd8CHh0nFt7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the QCNN on the digits dataset"
      ],
      "metadata": {
        "id": "D4QjN9yYF0CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits = datasets.load_digits()\n",
        "images, labels = digits.data, digits.target\n",
        "\n",
        "images = images[np.where((labels == 0) | (labels == 1))]\n",
        "labels = labels[np.where((labels == 0) | (labels == 1))]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=12, figsize=(3, 1))\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    ax.imshow(images[i].reshape((8, 8)), cmap=\"gray\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cadgVyXIF2pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_digits_data(num_train, num_test, rng):\n",
        "    \"\"\"Return training and testing data of digits dataset.\"\"\"\n",
        "    digits = datasets.load_digits()\n",
        "    features, labels = digits.data, digits.target\n",
        "\n",
        "    # only use first two classes\n",
        "    features = features[np.where((labels == 0) | (labels == 1))]\n",
        "    labels = labels[np.where((labels == 0) | (labels == 1))]\n",
        "\n",
        "    # normalize data\n",
        "    features = features / np.linalg.norm(features, axis=1).reshape((-1, 1))\n",
        "\n",
        "    # subsample train and test split\n",
        "    train_indices = rng.choice(len(labels), num_train, replace=False)\n",
        "    test_indices = rng.choice(\n",
        "        np.setdiff1d(range(len(labels)), train_indices), num_test, replace=False\n",
        "    )\n",
        "\n",
        "    x_train, y_train = features[train_indices], labels[train_indices]\n",
        "    x_test, y_test = features[test_indices], labels[test_indices]\n",
        "\n",
        "    return (\n",
        "        jnp.asarray(x_train),\n",
        "        jnp.asarray(y_train),\n",
        "        jnp.asarray(x_test),\n",
        "        jnp.asarray(y_test),\n",
        "    )"
      ],
      "metadata": {
        "id": "aly7p_-EF7i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def compute_out(weights, weights_last, features, labels):\n",
        "    \"\"\"Computes the output of the corresponding label in the qcnn\"\"\"\n",
        "    cost = lambda weights, weights_last, feature, label: conv_net(weights, weights_last, feature)[\n",
        "        label\n",
        "    ]\n",
        "    return jax.vmap(cost, in_axes=(None, None, 0, 0), out_axes=0)(\n",
        "        weights, weights_last, features, labels\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_accuracy(weights, weights_last, features, labels):\n",
        "    \"\"\"Computes the accuracy over the provided features and labels\"\"\"\n",
        "    out = compute_out(weights, weights_last, features, labels)\n",
        "    return jnp.sum(out > 0.5) / len(out)\n",
        "\n",
        "\n",
        "def compute_cost(weights, weights_last, features, labels):\n",
        "    \"\"\"Computes the cost over the provided features and labels\"\"\"\n",
        "    out = compute_out(weights, weights_last, features, labels)\n",
        "    return 1.0 - jnp.sum(out) / len(labels)\n",
        "\n",
        "\n",
        "def init_weights():\n",
        "    \"\"\"Initializes random weights for the QCNN model.\"\"\"\n",
        "    weights = pnp.random.normal(loc=0, scale=1, size=(18, 2), requires_grad=True)\n",
        "    weights_last = pnp.random.normal(loc=0, scale=1, size=4 ** 2 - 1, requires_grad=True)\n",
        "    return jnp.array(weights), jnp.array(weights_last)\n",
        "\n",
        "\n",
        "value_and_grad = jax.jit(jax.value_and_grad(compute_cost, argnums=[0, 1]))"
      ],
      "metadata": {
        "id": "kI6jInbNF8Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_qcnn(n_train, n_test, n_epochs):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        n_train  (int): number of training examples\n",
        "        n_test   (int): number of test examples\n",
        "        n_epochs (int): number of training epochs\n",
        "        desc  (string): displayed string during optimization\n",
        "\n",
        "    Returns:\n",
        "        dict: n_train,\n",
        "        steps,\n",
        "        train_cost_epochs,\n",
        "        train_acc_epochs,\n",
        "        test_cost_epochs,\n",
        "        test_acc_epochs\n",
        "\n",
        "    \"\"\"\n",
        "    # load data\n",
        "    x_train, y_train, x_test, y_test = load_digits_data(n_train, n_test, rng)\n",
        "\n",
        "    # init weights and optimizer\n",
        "    weights, weights_last = init_weights()\n",
        "\n",
        "    # learning rate decay\n",
        "    cosine_decay_scheduler = optax.cosine_decay_schedule(0.1, decay_steps=n_epochs, alpha=0.95)\n",
        "    optimizer = optax.adam(learning_rate=cosine_decay_scheduler)\n",
        "    opt_state = optimizer.init((weights, weights_last))\n",
        "\n",
        "    # data containers\n",
        "    train_cost_epochs, test_cost_epochs, train_acc_epochs, test_acc_epochs = [], [], [], []\n",
        "\n",
        "    for step in range(n_epochs):\n",
        "        # Training step with (adam) optimizer\n",
        "        train_cost, grad_circuit = value_and_grad(weights, weights_last, x_train, y_train)\n",
        "        updates, opt_state = optimizer.update(grad_circuit, opt_state)\n",
        "        weights, weights_last = optax.apply_updates((weights, weights_last), updates)\n",
        "\n",
        "        train_cost_epochs.append(train_cost)\n",
        "\n",
        "        # compute accuracy on training data\n",
        "        train_acc = compute_accuracy(weights, weights_last, x_train, y_train)\n",
        "        train_acc_epochs.append(train_acc)\n",
        "\n",
        "        # compute accuracy and cost on testing data\n",
        "        test_out = compute_out(weights, weights_last, x_test, y_test)\n",
        "        test_acc = jnp.sum(test_out > 0.5) / len(test_out)\n",
        "        test_acc_epochs.append(test_acc)\n",
        "        test_cost = 1.0 - jnp.sum(test_out) / len(test_out)\n",
        "        test_cost_epochs.append(test_cost)\n",
        "\n",
        "    return dict(\n",
        "        n_train=[n_train] * n_epochs,\n",
        "        step=np.arange(1, n_epochs + 1, dtype=int),\n",
        "        train_cost=train_cost_epochs,\n",
        "        train_acc=train_acc_epochs,\n",
        "        test_cost=test_cost_epochs,\n",
        "        test_acc=test_acc_epochs,\n",
        "    )"
      ],
      "metadata": {
        "id": "ExVM5j6EF-nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_test = 100\n",
        "n_epochs = 100\n",
        "n_reps = 100\n",
        "\n",
        "\n",
        "def run_iterations(n_train):\n",
        "    results_df = pd.DataFrame(\n",
        "        columns=[\"train_acc\", \"train_cost\", \"test_acc\", \"test_cost\", \"step\", \"n_train\"]\n",
        "    )\n",
        "\n",
        "    for _ in range(n_reps):\n",
        "        results = train_qcnn(n_train=n_train, n_test=n_test, n_epochs=n_epochs)\n",
        "        results_df = pd.concat(\n",
        "            [results_df, pd.DataFrame.from_dict(results)], axis=0, ignore_index=True\n",
        "        )\n",
        "\n",
        "    return results_df\n",
        "\n",
        "\n",
        "# run training for multiple sizes\n",
        "train_sizes = [2, 5, 10, 20, 40, 80]\n",
        "results_df = run_iterations(n_train=2)\n",
        "for n_train in train_sizes[1:]:\n",
        "    results_df = pd.concat([results_df, run_iterations(n_train=n_train)])"
      ],
      "metadata": {
        "id": "Q_pfcr6FGBDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate dataframe\n",
        "df_agg = results_df.groupby([\"n_train\", \"step\"]).agg([\"mean\", \"std\"])\n",
        "df_agg = df_agg.reset_index()\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "colors = sns.color_palette()\n",
        "fig, axes = plt.subplots(ncols=3, figsize=(16.5, 5))\n",
        "\n",
        "generalization_errors = []\n",
        "\n",
        "# plot losses and accuracies\n",
        "for i, n_train in enumerate(train_sizes):\n",
        "    df = df_agg[df_agg.n_train == n_train]\n",
        "\n",
        "    dfs = [df.train_cost[\"mean\"], df.test_cost[\"mean\"], df.train_acc[\"mean\"], df.test_acc[\"mean\"]]\n",
        "    lines = [\"o-\", \"x--\", \"o-\", \"x--\"]\n",
        "    labels = [fr\"$N={n_train}$\", None, fr\"$N={n_train}$\", None]\n",
        "    axs = [0,0,2,2]\n",
        "\n",
        "    for k in range(4):\n",
        "        ax = axes[axs[k]]\n",
        "        ax.plot(df.step, dfs[k], lines[k], label=labels[k], markevery=10, color=colors[i], alpha=0.8)\n",
        "\n",
        "\n",
        "    # plot final loss difference\n",
        "    dif = df[df.step == 100].test_cost[\"mean\"] - df[df.step == 100].train_cost[\"mean\"]\n",
        "    generalization_errors.append(dif)\n",
        "\n",
        "# format loss plot\n",
        "ax = axes[0]\n",
        "ax.set_title('Train and Test Losses', fontsize=14)\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "\n",
        "# format generalization error plot\n",
        "ax = axes[1]\n",
        "ax.plot(train_sizes, generalization_errors, \"o-\", label=r\"$gen(\\alpha)$\")\n",
        "ax.set_xscale('log')\n",
        "ax.set_xticks(train_sizes)\n",
        "ax.set_xticklabels(train_sizes)\n",
        "ax.set_title(r'Generalization Error $gen(\\alpha) = R(\\alpha) - \\hat{R}_N(\\alpha)$', fontsize=14)\n",
        "ax.set_xlabel('Training Set Size')\n",
        "\n",
        "# format loss plot\n",
        "ax = axes[2]\n",
        "ax.set_title('Train and Test Accuracies', fontsize=14)\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_ylim(0.5, 1.05)\n",
        "\n",
        "legend_elements = [\n",
        "    mpl.lines.Line2D([0], [0], label=f'N={n}', color=colors[i]) for i, n in enumerate(train_sizes)\n",
        "    ] + [\n",
        "    mpl.lines.Line2D([0], [0], marker='o', ls='-', label='Train', color='Black'),\n",
        "    mpl.lines.Line2D([0], [0], marker='x', ls='--', label='Test', color='Black')\n",
        "    ]\n",
        "\n",
        "axes[0].legend(handles=legend_elements, ncol=3)\n",
        "axes[2].legend(handles=legend_elements, ncol=3)\n",
        "\n",
        "axes[1].set_yscale('log', base=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05KxTgyrGIve"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pennylane-cpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-yZzPQ42CQ4j",
        "DkGu568DGn_O",
        "dzxee-EXE4qp"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}